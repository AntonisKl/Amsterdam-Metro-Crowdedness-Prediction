{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "371f32f7-754e-45e9-9527-40326a33de3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import time\n",
    "import pytz\n",
    "from workalendar.europe import Netherlands\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, mean_absolute_error\n",
    "\n",
    "import helpers_gvb_reworked_v2 as h\n",
    "\n",
    "import importlib   # to reload helpers without restarting kernel: importlib.reload(h)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "from time import time\n",
    "\n",
    "import warnings\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c55fc6d9-d881-4f33-a8ec-f66d8867776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stations to create predictions for\n",
    "stations = ['Centraal Station', 'Station Zuid']\n",
    "\n",
    "#change every week\n",
    "week_no = 48"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb85c76e-6769-49a0-8455-d76af88ca1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "today = pd.to_datetime(\"today\")\n",
    "today_str = str(today.year) + \"-\" + str(today.month) + \"-\" + str(today.day)\n",
    "covid_url = 'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/stringency/date-range/2020-09-01/' + today_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355a20c8-94c6-468b-9d43-3f502c1dc787",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd1595-1a70-4576-b244-e38c8f9e3e03",
   "metadata": {},
   "source": [
    "## 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f17a5588-e681-413d-b4e4-a6b500f83900",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading raw data\n"
     ]
    }
   ],
   "source": [
    "print('Start loading raw data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b726e7ef-c224-49ca-89f2-23b3ea01d830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 52.69049334526062 sec.\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "herkomst_2020 = h.get_gvb_data ('Datalab_Reis_Herkomst_Uur_')\n",
    "bestemming_2020 = h.get_gvb_data ('Datalab_Reis_Bestemming_Uur_')\n",
    "\n",
    "t2 = time()\n",
    "print('Completed in %s sec.' % (str(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cea3eb85-26c0-4bd3-a766-b44355680d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 0.5435638427734375 sec.\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "herkomst_2021 = h.get_gvb_data ('Datalab_Reis_Herkomst_Uur_2021')\n",
    "bestemming_2021 = h.get_gvb_data ('Datalab_Reis_Bestemming_Uur_2021')\n",
    "\n",
    "t2 = time()\n",
    "print('Completed in %s sec.' % (str(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e04ec78a-b121-4566-b628-30a97d352027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 2.298098564147949 sec.\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "knmi_obs = h.get_knmi_data('knmi/knmi-observations/2021/**/**/*')\n",
    "\n",
    "t2 = time()\n",
    "print('Completed in %s sec.' % (str(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5d7cb88-8398-41a3-bc2a-32ae7129794d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed in 47.235177755355835 sec.\n"
     ]
    }
   ],
   "source": [
    "t1 = time()\n",
    "\n",
    "knmi_preds = h.get_knmi_data('knmi/knmi/2021/**/**/*.json.gz')\n",
    "\n",
    "t2 = time()\n",
    "print('Completed in %s sec.' % (str(t2 - t1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0cb87654-b7a8-4154-8985-b06fc142c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df_raw = pd.DataFrame(requests.get(url = covid_url).json()['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff861a54-6dfe-4fb7-b145-b5f038bfda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_data_raw = Netherlands().holidays(2019) + Netherlands().holidays(2020) + Netherlands().holidays(2021) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1910e17f-4eb8-481c-b69f-e73676ffb16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vacations_df = h.get_vacations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21c4b84b-2d20-4305-b54e-84257743014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Locatie      Datum Start show\n",
      "0               paradisoadam 2021-11-28   17:00:00\n",
      "1               paradisoadam 2021-01-24   12:00:00\n",
      "2               paradisoadam 2021-10-15   10:00:00\n",
      "3               paradisoadam 2021-11-09   14:00:00\n",
      "4               paradisoadam 2021-06-21   13:00:00\n",
      "..                       ...        ...        ...\n",
      "339  beursvanberlageofficial 2021-12-30   18:00:00\n",
      "340  beursvanberlageofficial 2021-11-09   15:00:00\n",
      "341  beursvanberlageofficial 2020-12-14   09:00:00\n",
      "342            concertgebouw 2021-04-18   10:30:00\n",
      "343            concertgebouw 2020-08-24   10:00:00\n",
      "\n",
      "[344 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "events = h.get_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c931817f-1d6a-4105-9f71-b50593c0600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_dir(dir):\n",
    "    \n",
    "    read_csv_beta = pd.read_csv(dir,sep=',')\n",
    "    \n",
    "    return read_csv_beta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3127687a-cf5d-4a86-bf70-9a77565d40e3",
   "metadata": {},
   "source": [
    "### 2. Prepare data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b56f9f-0042-4b6a-b412-d9c0206d71a9",
   "metadata": {},
   "source": [
    "#### Pre-process data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b582eda2-b772-4555-8b36-deb543cf62d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start pre-processing data\n"
     ]
    }
   ],
   "source": [
    "print('Start pre-processing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "835e35c1-e1b7-472b-9c10-5cfcc85dc4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "herkomst = pd.concat([herkomst_2020, herkomst_2021])\n",
    "bestemming = pd.concat([bestemming_2020, bestemming_2021])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b81c9bbf-884e-4ffb-8e99-93906290eb85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast 'AantalReizen' to int to sum up\n",
    "bestemming['AantalReizen'] = bestemming['AantalReizen'].astype(int)\n",
    "herkomst['AantalReizen'] = herkomst['AantalReizen'].astype(int)\n",
    "\n",
    "# Remove all duplicates\n",
    "bestemming.drop_duplicates(inplace=True)\n",
    "herkomst.drop_duplicates(inplace=True)\n",
    "\n",
    "# Group by station name because we are analysing per station\n",
    "bestemming_grouped = bestemming.groupby(['Datum', 'UurgroepOmschrijving (van aankomst)', 'AankomstHalteNaam'], as_index=False)['AantalReizen'].sum()\n",
    "herkomst_grouped = herkomst.groupby(['Datum', 'UurgroepOmschrijving (van vertrek)', 'VertrekHalteNaam'], as_index=False)['AantalReizen'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8174eafa-f23b-46ad-a687-d7ca7ff55c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestemming_herkomst = h.merge_bestemming_herkomst(bestemming_grouped, herkomst_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da1f5aa9-eadd-46e2-8cb1-52577b58ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvb_dfs = []\n",
    "\n",
    "for station in stations:\n",
    "    gvb_dfs.append(h.preprocess_gvb_data_for_modelling(bestemming_herkomst, station))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c6a2d1f-a539-4f52-83a3-a68b49800218",
   "metadata": {},
   "outputs": [],
   "source": [
    "knmi_historical = h.preprocess_knmi_data_hour(knmi_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b60da48-3d80-433d-83b9-3bf0dcd1dc2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "knmi_forecast = h.preprocess_metpre_data(knmi_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a01b8a02-3695-4fe0-84a2-2ce74c370b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = h.preprocess_covid_data(covid_df_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57e643b4-5be9-4962-b62f-b9fe1d883c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = h.preprocess_holiday_data(holidays_data_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d57b9801-7023-4b93-bdc9-f03ed0383209",
   "metadata": {},
   "source": [
    "#### Merge datasources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcd1f919-1efb-4984-a8ec-778a5d773a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvb_dfs_merged = []\n",
    "\n",
    "for df in gvb_dfs:\n",
    "    gvb_dfs_merged.append(h.merge_gvb_with_datasources(df, knmi_historical, covid_df, holiday_df, vacations_df, events))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "# for df in gvb_dfs_merged:\n",
    "#     print(df['planned_event'].head(100))\n",
    "#     df['planned_event'] = np.where(df['planned_event'] > 0, 1, 0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "# gvb_dfs_merged[0][gvb_dfs_merged[0]['planned_event'] != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "4d7d1211-44c6-4402-9f74-cc72aa6780c2",
   "metadata": {},
   "source": [
    "### 3. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2f20d89f-de7a-492f-92f4-c41980dc78f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start cleaning data\n"
     ]
    }
   ],
   "source": [
    "print('Start cleaning data')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e768f-9509-4ab1-be6a-d76168e936a9",
   "metadata": {},
   "source": [
    "#### Interpolate missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e084dfb-13cb-44ac-a3df-fb535640619f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:557: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  checkins_interpolator.fit(X_train, y_train)\n",
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:567: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  checkouts_interpolator.fit(X_train, y_train)\n",
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:557: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  checkins_interpolator.fit(X_train, y_train)\n",
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:567: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  checkouts_interpolator.fit(X_train, y_train)\n"
     ]
    }
   ],
   "source": [
    "gvb_dfs_interpolated = []\n",
    "\n",
    "for df in gvb_dfs_merged:\n",
    "    gvb_dfs_interpolated.append(h.interpolate_missing_values(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "# gvb_dfs_interpolated[0][gvb_dfs_interpolated[0]['planned_event'] != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a74407b-f2c2-47fe-80e8-1cce42578096",
   "metadata": {},
   "outputs": [],
   "source": [
    "gvb_dfs_final = []\n",
    "\n",
    "for df in gvb_dfs_interpolated:\n",
    "    \n",
    "    df['check-ins'] = df['check-ins'].astype(int)\n",
    "    df['check-outs'] = df['check-outs'].astype(int)\n",
    "    df[['check-ins_week_ago', 'check-outs_week_ago']] = df.apply(lambda x: h.get_crowd_last_week(df, x), axis=1, result_type=\"expand\")\n",
    "    \n",
    "    gvb_dfs_final.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [],
   "source": [
    "# gvb_dfs_final[0][gvb_dfs_final[0]['planned_event'] != 0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "id": "65eb849a-ec42-4294-9be1-0219214489b4",
   "metadata": {},
   "source": [
    "#### 4. Create model dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [],
   "source": [
    "# Define features and targets. This is the same for all stations at the moment.\n",
    "features = ['year', 'month', 'weekday', 'hour', 'holiday', 'vacation', 'planned_event',  'stringency', 'temperature', 'wind_speed', 'precipitation_h','global_radiation']\n",
    "\n",
    "targets = ['check-ins', 'check-outs']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "41fb8175-9821-417f-ad97-80e4fb208ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits = []\n",
    "\n",
    "for df in gvb_dfs_final:\n",
    "    df = df[['datetime'] + features + targets]\n",
    "\n",
    "    train, validation, test = h.get_train_val_test_split(df.dropna())\n",
    "    data_splits.append([train, validation, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b1e98d94-c94e-4a01-9c71-53bebe681eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_splits = []\n",
    "y_train_splits = []\n",
    "\n",
    "X_validation_splits = []\n",
    "y_validation_splits = []\n",
    "\n",
    "X_test_splits = []\n",
    "y_test_splits = []\n",
    "\n",
    "for split in data_splits:\n",
    "    \n",
    "    X_train_splits.append(split[0][features])\n",
    "    y_train_splits.append(split[0][targets])\n",
    "    \n",
    "    X_validation_splits.append(split[1][features])\n",
    "    y_validation_splits.append(split[1][targets])\n",
    "    \n",
    "    X_test_splits.append(split[2][features])\n",
    "    y_test_splits.append(split[2][targets])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0c728873-6baf-4750-97a1-248b60fbf302",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_crowd_last_week(df, row):\n",
    "#     week_ago = row['datetime'] - timedelta(weeks=1)\n",
    "#     subset_with_hour = df[(df['datetime']==week_ago) & (df['hour']==row['hour'])]\n",
    "#\n",
    "#     # If crowd from last week is not available at exact date- and hour combination, then get average crowd of last week.\n",
    "#     subset_week_ago = df[(df['year']==row['year']) & (df['week']==row['week']) & (df['hour']==row['hour'])]\n",
    "#\n",
    "#     checkins_week_ago = 0\n",
    "#     checkouts_week_ago = 0\n",
    "#\n",
    "#     if len(subset_with_hour) > 0: # return crowd from week ago at the same day/time (hour)\n",
    "#         checkins_week_ago = subset_with_hour['check-ins'].mean()\n",
    "#         checkouts_week_ago = subset_with_hour['check-outs'].mean()\n",
    "#     elif len(subset_week_ago) > 0: # return average crowd the hour group a week ago\n",
    "#         checkins_week_ago = subset_week_ago['check-ins'].mean()\n",
    "#         checkouts_week_ago = subset_week_ago['check-outs'].mean()\n",
    "#\n",
    "#     return [checkins_week_ago, checkouts_week_ago]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76a69e4d-ac43-439a-8a5d-cbceb6f6c592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['peak_period'][df.hour.isin([7,8,17,18])] = 1\n",
      "C:\\Users\\Antonis\\Documents\\UvA\\DSP\\DSP-project\\model\\helpers_gvb_reworked_v2.py:677: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['peak_period'][df.hour.isin([7,8,17,18])] = 1\n"
     ]
    }
   ],
   "source": [
    "# Dataframes to predict cdfheck-ins and check-outs of next week\n",
    "X_predict_dfs = []\n",
    "\n",
    "for df in gvb_dfs_final:\n",
    "    X_predict_dfs.append(h.get_future_df(features, df, covid_df.tail(1)['stringency'][0], holiday_df, vacations_df, knmi_forecast, events))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6772335-e1de-49ff-97d7-91aa0b88e55d",
   "metadata": {},
   "source": [
    "### 5. Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f317ef00-853b-4a79-bfbc-8f896d11c2dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start modelling\n"
     ]
    }
   ],
   "source": [
    "print('Start modelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "092720fd-1f79-438b-a374-376b199d5b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "2"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ad550a4-3be4-4a35-ae76-0c8503936c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_models = []\n",
    "\n",
    "for x in range(0, len(data_splits)):\n",
    "    model_basic, r_squared_basic, mae_basic, rmse_basic = h.train_random_forest_regressor(X_train_splits[x], y_train_splits[x], \n",
    "                                                                                          X_validation_splits[x], y_validation_splits[x], \n",
    "                                                                                          None)\n",
    "    basic_models.append([model_basic, r_squared_basic, mae_basic, rmse_basic])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1dffd19a-7d34-4289-a22b-36e4764559b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Tune (hyper-)parameters (not done because models currently do not improve with hyperparameter tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b09f27e1-da31-4c14-a527-2f61098953c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify hyperparameters, these could be station-specific. For now, default hyperparameter settings are being used.\n",
    "centraal_station_hyperparameters = None\n",
    "station_zuid_hyperparameters = None\n",
    "#station_bijlmer_arena_hyperparameters = 2\n",
    "\n",
    "hyperparameters = [centraal_station_hyperparameters,\n",
    "                  station_zuid_hyperparameters\n",
    "#                  ,station_bijlmer_arena_hyperparameters\n",
    "                  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b67902c5-cf1f-436c-a72a-df00f96dba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_models = []\n",
    "\n",
    "#for x in range(0, len(data_splits)):\n",
    "#    model_tuned, r_squared_tuned, mae_tuned, rmse_tuned = h.train_random_forest_regressor(X_train_splits[x], y_train_splits[x], \n",
    "#                                                                                          X_validation_splits[x], y_validation_splits[x], \n",
    "#                                                                                          hyperparameters[x])\n",
    "#    tuned_models.append([model_tuned, r_squared_tuned, mae_tuned, rmse_tuned])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d926de2-7a56-4a63-a7d4-9b9403b583c4",
   "metadata": {},
   "source": [
    "##### Improvements compared to basic model (negative is worse performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2ad3a4ec-60c9-4dcc-ba5f-fd318c6de61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for x in range(0, len(basic_models)):\n",
    "#    print(\"R-squared difference\", tuned_models[x][1]-basic_models[x][1])\n",
    "#    print(\"MAE difference\", tuned_models[x][2]-basic_models[x][2])\n",
    "#    print(\"RMSE difference\", tuned_models[x][3]-basic_models[x][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6304b2-cd18-45c8-8ead-3838a91a64c0",
   "metadata": {},
   "source": [
    "#### Train test model (including validation data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e297874d-3e42-43e6-8cbd-e5d48b248cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_models = []\n",
    "\n",
    "for x in range(0, len(data_splits)):\n",
    "    X_train_with_val = pd.concat([X_train_splits[x], X_validation_splits[x]])\n",
    "    y_train_with_val = pd.concat([y_train_splits[x], y_validation_splits[x]])\n",
    "    \n",
    "    model_test, r_squared_test, mae_test, rmse_test = h.train_random_forest_regressor(X_train_with_val, y_train_with_val, \n",
    "                                                                                          X_test_splits[x], y_test_splits[x], \n",
    "                                                                                          hyperparameters[x])\n",
    "    test_models.append([model_test, r_squared_test, mae_test, rmse_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "feac597b-0548-42ff-ae3c-5e9e402e7f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "[[RandomForestRegressor(random_state=1),\n  0.891301419803745,\n  106.57626811594201,\n  158.07635057309253],\n [RandomForestRegressor(random_state=1),\n  0.8525079173189607,\n  76.41847656249999,\n  104.97004454210678]]"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e133fdfe-ddda-4ba9-9737-0d764a82700e",
   "metadata": {},
   "source": [
    "#### Check models on R-squared score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5383320e-a263-4c6c-9833-eaeea8f3ebff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0, len(test_models)):\n",
    "    station_name = stations[x]\n",
    "    r_squared = test_models[x][1]\n",
    "    if r_squared < 0.7:\n",
    "        warnings.warn(\"Model for \" + station_name + \" shows unexpected performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d28f4-1741-4a87-af98-89f47463f052",
   "metadata": {},
   "source": [
    "#### Train final models (to make predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1d51d1e7-6244-47e7-bde7-2c964ac691d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_models = []\n",
    "\n",
    "for x in range(0, len(data_splits)):\n",
    "    X_train_with_val = pd.concat([X_train_splits[x], X_validation_splits[x], X_test_splits[x]])\n",
    "    y_train_with_val = pd.concat([y_train_splits[x], y_validation_splits[x], y_test_splits[x]])\n",
    "    \n",
    "    model_final = h.train_random_forest_regressor(X_train_with_val, y_train_with_val, X_test_splits[x], y_test_splits[x], \n",
    "                                                  hyperparameters[x])[0]\n",
    "    final_models.append(model_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d0a5cbe-b334-4465-8e73-8d98d3073826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing data\n"
     ]
    }
   ],
   "source": [
    "print('Start preparing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e6b77ae2-061e-4090-b35a-88b927f26fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for predict_df in X_predict_dfs:\n",
    "    for model in final_models:\n",
    "        prediction = h.predict(model, predict_df.dropna())\n",
    "        predictions.append(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca90fb8-96c1-4445-aa6f-ca030bcd2924",
   "metadata": {},
   "source": [
    "### 6. Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "#today = pd.to_datetime(\"today\")\n",
    "#today_str = str(today.year) + str(today.month) + str(today.day)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "adc28452-dcf4-4a83-ab29-69ae76d2b505",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0].to_csv(('output/prediction_all_week_' + str(week_no) + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b260b0-6f04-4d65-910e-746439e0d5da",
   "metadata": {},
   "source": [
    "### 7. Make graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "abdd6661-fd7e-4d56-9ec1-38b2adee60ad",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data_bestemming/Datalab_Reis_Bestemming_Uur_20220106.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-59-02eb385160ed>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdf_best_1\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"{}.csv\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoday\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'%Y%m%d'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\";\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdf_best_2\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"{}.csv\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoday\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m7\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'%Y%m%d'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\";\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdf_best_3\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"{}.csv\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoday\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m14\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'%Y%m%d'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\";\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mdf_best_4\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"\u001B[0m\u001B[1;33m+\u001B[0m\u001B[1;34m\"{}.csv\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtoday\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mtimedelta\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdays\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m28\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mstrftime\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'%Y%m%d'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msep\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\";\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001B[0m\n\u001B[0;32m    608\u001B[0m     \u001B[0mkwds\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mupdate\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkwds_defaults\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    609\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 610\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    611\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_read\u001B[1;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[0;32m    460\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[1;31m# Create the parser.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 462\u001B[1;33m     \u001B[0mparser\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    463\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    464\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[0;32m    817\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"has_index_names\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    818\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 819\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[1;34m(self, engine)\u001B[0m\n\u001B[0;32m   1048\u001B[0m             )\n\u001B[0;32m   1049\u001B[0m         \u001B[1;31m# error: Too many arguments for \"ParserBase\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1050\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmapping\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mengine\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# type: ignore[call-arg]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1051\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1052\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_failover_to_python\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, src, **kwds)\u001B[0m\n\u001B[0;32m   1865\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1866\u001B[0m         \u001B[1;31m# open handles\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1867\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_open_handles\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1868\u001B[0m         \u001B[1;32massert\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mhandles\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1869\u001B[0m         \u001B[1;32mfor\u001B[0m \u001B[0mkey\u001B[0m \u001B[1;32min\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;34m\"storage_options\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"encoding\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"memory_map\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;34m\"compression\"\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001B[0m in \u001B[0;36m_open_handles\u001B[1;34m(self, src, kwds)\u001B[0m\n\u001B[0;32m   1360\u001B[0m         \u001B[0mLet\u001B[0m \u001B[0mthe\u001B[0m \u001B[0mreaders\u001B[0m \u001B[0mopen\u001B[0m \u001B[0mIOHanldes\u001B[0m \u001B[0mafter\u001B[0m \u001B[0mthey\u001B[0m \u001B[0mare\u001B[0m \u001B[0mdone\u001B[0m \u001B[1;32mwith\u001B[0m \u001B[0mtheir\u001B[0m \u001B[0mpotential\u001B[0m \u001B[0mraises\u001B[0m\u001B[1;33m.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1361\u001B[0m         \"\"\"\n\u001B[1;32m-> 1362\u001B[1;33m         self.handles = get_handle(\n\u001B[0m\u001B[0;32m   1363\u001B[0m             \u001B[0msrc\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1364\u001B[0m             \u001B[1;34m\"r\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001B[0m in \u001B[0;36mget_handle\u001B[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[0;32m    640\u001B[0m                 \u001B[0merrors\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"replace\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    641\u001B[0m             \u001B[1;31m# Encoding\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 642\u001B[1;33m             handle = open(\n\u001B[0m\u001B[0;32m    643\u001B[0m                 \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    644\u001B[0m                 \u001B[0mioargs\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmode\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data_bestemming/Datalab_Reis_Bestemming_Uur_20220106.csv'"
     ]
    }
   ],
   "source": [
    "df_best_1 = pd.read_csv(\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"+\"{}.csv\".format((today - timedelta(days=0)).strftime('%Y%m%d')), sep = \";\")\n",
    "df_best_2 = pd.read_csv(\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"+\"{}.csv\".format((today - timedelta(days=7)).strftime('%Y%m%d')), sep = \";\")\n",
    "df_best_3 = pd.read_csv(\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"+\"{}.csv\".format((today - timedelta(days=14)).strftime('%Y%m%d')), sep = \";\")\n",
    "df_best_4 = pd.read_csv(\"data_bestemming/Datalab_Reis_Bestemming_Uur_\"+\"{}.csv\".format((today - timedelta(days=28)).strftime('%Y%m%d')), sep = \";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ef0ee5-d01e-46dc-aed7-bbbabc4c32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best = h.preprocess_gvb_data(pd.concat([df_best_1, df_best_2, df_best_3, df_best_4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076ec5b7-2c41-4dcd-aaaf-c07b0c3433c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_weekday = df_best[df_best['weekday'].isin([0,1,2,3,4])]\n",
    "df_best_weekend = df_best[df_best['weekday'].isin([5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fe4e9d-ebef-47f5-8bda-826eb1a186c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_weekday = df_best_weekday[df_best_weekday['arrival_stop_name'] == 'Centraal Station']\n",
    "df_best_weekend = df_best_weekend[df_best_weekend['arrival_stop_name'] == 'Centraal Station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b81f4e-012a-4877-a0ce-95b4ee269fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_weekday_grouped = df_best_weekday.groupby('week').sum().reset_index()\n",
    "df_best_weekend_grouped = df_best_weekend.groupby('week').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76869efd-b6f5-436e-b0a9-834aaeab77f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_weekday_grouped = df_best_weekday_grouped[df_best_weekday_grouped.week.isin([week_no-1, week_no-2, week_no-3, week_no-4])]\n",
    "df_best_weekend_grouped = df_best_weekend_grouped[df_best_weekend_grouped.week.isin([week_no-1, week_no-2, week_no-3, week_no-4])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3c5dd-5b52-41db-8be5-59f242c8d5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_best_weekday_grouped = df_best_weekday_grouped[['week','count']]\n",
    "df_best_weekend_grouped = df_best_weekend_grouped[['week','count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aba10a-06e1-4ebf-aec3-1bbfae6ecbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]['week'] = predictions[0]['datetime'].dt.isocalendar().week  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56fa609-82f8-4d09-a388-dae634a57a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weekdays = predictions[0][predictions[0].weekday.isin([0,1,2,3,4])]\n",
    "pred_weekends = predictions[0][predictions[0].weekday.isin([5,6])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e9fc95-52d2-46c3-b6ed-05e2cae51e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_weekdays = pred_weekdays[['week','check-outs_predicted']].groupby('week').sum().rename(columns={'check-outs_predicted':'count'}).reset_index()\n",
    "pred_weekends = pred_weekends[['week','check-outs_predicted']].groupby('week').sum().rename(columns={'check-outs_predicted':'count'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50dba8a6-9654-4ad4-af31-6ed17a2ee715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_weekday = pd.concat([df_best_weekday_grouped, pred_weekdays])\n",
    "df_plot_weekend = pd.concat([df_best_weekend_grouped, pred_weekends])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6722c7-6745-436b-88f7-51b2b1b77d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_weekday['count'] = df_plot_weekday['count'] / 5\n",
    "df_plot_weekend['count'] = df_plot_weekend['count'] / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a1f72e-108c-4e8a-b858-2abb26bea21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot_weekday[\"color\"] = \"blue\" \n",
    "df_plot_weekday[\"color\"][df_plot_weekday[\"week\"] == week_no] = \"lightskyblue\"   # Change each week\n",
    "#df_plot[\"color\"][df_plot[\"week_year\"].isin([\"9 ('20)\", \"13 ('20)\", \"39 ('20)\"])] = \"lightblue\"  # Change each week\n",
    "\n",
    "df_plot_weekend[\"color\"] = \"blue\" \n",
    "df_plot_weekend[\"color\"][df_plot_weekend[\"week\"] == week_no] = \"lightskyblue\"   # Change each week\n",
    "#df_plot[\"color\"][df_plot[\"week_year\"].isin([\"9 ('20)\", \"13 ('20)\", \"39 ('20)\"])] = \"lightblue\"  # Change each week\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fdf095-a8d1-46f4-a31d-e713ef9b1b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4524df-ab9b-4f2e-a515-214bd6fbc8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (11,4), dpi = 100, frameon = False, sharey = True, constrained_layout = True)\n",
    "\n",
    "ax1.bar(x = df_plot_weekday['week'], height = df_plot_weekday['count'], color = df_plot_weekday['color'])\n",
    "ax1.set_title('Doordeweeks (ma-vr)')\n",
    "ax1.set_xlabel(\"Week\")\n",
    "ax1.set_ylabel(\"Aantal Reis-uitchecks per dag \\n\")\n",
    "ax1.spines['right'].set_visible(False)\n",
    "ax1.spines['top'].set_visible(False)\n",
    "ax1.grid(axis = 'y', color = 'lightgrey')\n",
    "\n",
    "ax2.bar(x = df_plot_weekend['week'], height = df_plot_weekend['count'], color = df_plot_weekend['color'])\n",
    "ax2.set_title('Weekend (za-zo)')\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.grid(axis = 'y', color = 'lightgrey')\n",
    "ax2.set_xlabel(\"Week\")\n",
    "\n",
    "gemeten = mpatches.Patch(color='blue', label='Gemeten')\n",
    "voorspelling = mpatches.Patch(color='lightskyblue', label='Voorspelling')\n",
    "plt.legend(handles=[gemeten, voorspelling], bbox_to_anchor=(1.2, 0.5, 0.5, 0.5))\n",
    "\n",
    "ax2.spines['right'].set_visible(False)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.grid(axis = 'y', color = 'lightgrey')\n",
    "plt.rcParams[\"axes.axisbelow\"] = True\n",
    "\n",
    "fig.suptitle('Centraal Station (Metro)\\n', fontsize = 18)\n",
    "\n",
    "my_filename = \"output/weekly_report_gvb_prediction_\" + today_str + \".png\" \n",
    "        \n",
    "plt.savefig(my_filename, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd443ddf-5621-4fff-8548-c7be7761295b",
   "metadata": {},
   "source": [
    "### 8. Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07d3407-b7f3-4213-be74-9c4021d8ee77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def read_csv_dir(dir):\n",
    "    \n",
    "    \n",
    "#     fields = ['datetime', 'predict_xg_CMSA-GAKH-01', 'predict_xg_GACM-02', 'predict_xg_CMSA-GAWW-15', 'predict_xg_CMSA-GAWW-14']\n",
    "#    dateparse = lambda x: datetime.strptime(x, '%Y-%m-%d %H:%M:%S%z')\n",
    "#    read_csv_beta = pd.read_csv(dir,sep=','\n",
    "                                #usecols=fields\n",
    "#                               )\n",
    "    \n",
    "#    return read_csv_beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c395dc7e-d2ae-4dd1-ac05-67249f4a4780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read csv files from the previous week\n",
    "#df_pred = pd.concat(map(read_csv_dir, glob.glob(\"output/prediction_all_week_*.csv\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ce98d3d-8328-4555-8a6e-01b9953dec30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#predicted counts\n",
    "#df_pred['datetime'] = df_pred['hour'] + + df['datetime']\n",
    "#df_pred['datetime'] = pd.to_datetime(df_pred['datetime'])\n",
    "#df_pred = df_pred.set_index('datetime')\n",
    "#df_pred['week'] = df_pred.index.isocalendar().week\n",
    "#slices data from only the last 4 weeks\n",
    "#df_pred = df_pred[df_pred['week'].isin([my_week-1, my_week-2, my_week-3])]\n",
    "#df_pred = df_pred.groupby('week').sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "myenv",
   "language": "python",
   "display_name": "Python (myenv)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}