{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do's:\n",
    "- When there is a larger set of data with weather predictions (after 2021/06/15), remove weather observations and switch to only using weather predictions\n",
    "- Update list of locations to use in report\n",
    "- Improve/validate prediction model based on above changes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resono 1 week predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 1 week-ahead predictions of the visitor counts (hourly visitor counts based on historic data) for all locations (in druktebeeld) or a list of Resono locations. \n",
    "\n",
    "Generate a graph with the predictions for in the weekly report for each location. The graph will be automatically saved in the directory that you can set in the arguments section. \n",
    "\n",
    "Predictions are stored in a data frame with the following additional columns: \n",
    "- **'total_count_predicted'**: predicted total counts (for the next 7 days per location)\n",
    "- **'data_version'**: version of the data (feature set)\n",
    "- **'model_version'**: version of the model (type and settings)\n",
    "- **'predicted_at'**: timestamp of prediction (moment prediction was made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information for when using this notebook:\n",
    "\n",
    "Data file needed: \n",
    "- Hourly total counts of historic Resono data (retrieved from Resono dashboard)\n",
    "\n",
    "Current model:\n",
    "- Linear regression (based on validation with 7 weeks for selection of locations, against baseline model (repeat past week))\n",
    "\n",
    "Model input current version:\n",
    "- Past observations Resono data (average past few weeks etc.)\n",
    "- Periodic data (time of day etc.)\n",
    "- Stringency Index\n",
    "- Holiday data\n",
    "- Vacation data\n",
    "- Weather data **observations** (< 2021/06/15), and **predictions** (>= 2021/06/15) (temperature, wind speed, global radiation, cloud cover)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "Change directory to folder that contains the function files/database credentials in code blocks below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    # (Re-)Installs packages.\n",
    "    \n",
    "    get_ipython().run_cell_magic('bash', '', 'pip install imblearn\\npip install xgboost\\npip install mord\\npip install psycopg2-binary\\npip install workalendar\\npip install eli5\\n pip install plotly')\n",
    "    \n",
    "    import pandas as pd\n",
    "    pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.24.2  # Run if sklearn error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"/home/jovyan/Credentials\") # Directory with Azure DB credentials\n",
    "import env_az\n",
    "\n",
    "os.chdir(\"/home/jovyan/gitops/central_storage_analyses/notebooks_predictions/resono_week\")\n",
    "import prediction_model_helpers as h  # Universal predictions\n",
    "import resono_week_predictions as resono_pred  # Resono 1 week model specific\n",
    "\n",
    "import importlib  # For when coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments for functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file name of historic Resono data (total daily counts)\n",
    "resono_data_dir = \"/home/jovyan/Resono_1week_predictions\"\n",
    "file_name = '2021-01-01_2021-06-23_totalsperhour.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of sampling for data source to predict\n",
    "freq = 'H'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples in a day\n",
    "n_samples_day = 24\n",
    "# how many samples in a week\n",
    "n_samples_week = 24*7\n",
    "# what period to predict for operational forecast (samples)\n",
    "predict_period = n_samples_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column name(s) of variabe to predict (can also be \"all\")\n",
    "#Y_names = \"all\" \n",
    "Y_names = ['Albert Cuyp', 'Vondelpark West', 'Rembrandtplein',\n",
    "          'Nieuwmarkt', 'Leidseplein', 'Kalverstraat Noord', 'Kalverstraat Zuid']\n",
    "\n",
    "# data source (for which the predictions are made)\n",
    "data_source = 'resono'\n",
    "\n",
    "# type of prediction (count -> regression or level -> classification)\n",
    "target = 'count'  # Can only be count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for starting of learnset \n",
    "start_learnset = h.get_start_learnset(train_length = 20, date_str = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for start prediction\n",
    "start_prediction = \"2021-06-28 00:00:00\"  # start date of week to predict \n",
    "start_prediction = pd.to_datetime(start_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of training samples needed to make predictions (otherwise no predictions for that location)\n",
    "min_train_samples = n_samples_week*4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform outlier removal (\"yes\" or \"no\")\n",
    "outlier_removal = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set versions (for storing results)\n",
    "current_model_version = 'lr_0_0'\n",
    "current_data_version = \"1_0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report graph settings\n",
    "report_dir = \"/home/jovyan/Resono_1week_predictions/\"\n",
    "week_label = \"26\"\n",
    "legend = \"yes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df, resono_df, resono_df_raw, start_prediction, end_prediction, Y_names_all = resono_pred.prepare_data(env_az,\n",
    "                                                                                                            resono_data_dir,\n",
    "                                                                                                            file_name,\n",
    "                                                                                                           freq, \n",
    "                                                                                                           predict_period, \n",
    "                                                                                                           start_prediction,\n",
    "                                                                                                            n_samples_day, \n",
    "                                                                                                           Y_names, \n",
    "                                                                                                           target,\n",
    "                                                                                                           start_learnset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Make predictions and store in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- remove in version without backtesting\n",
    "prepared_dfs = dict()\n",
    "y_scalers = dict()\n",
    "# ---\n",
    "\n",
    "# Initialize data frame with predictions\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Predict for each location\n",
    "for idx, Y in enumerate(Y_names_all):\n",
    "    \n",
    "    # Show location\n",
    "    print(Y)\n",
    "    \n",
    "    # Preprocessed data frame for this location\n",
    "    preprocessed_df = resono_pred.get_location_df(base_df, resono_df, Y)\n",
    "    \n",
    "    # Gather predictons for this location\n",
    "    prepared_df, predictions, y_scaler = resono_pred.get_resono_predictions(preprocessed_df, resono_df_raw, freq, predict_period, n_samples_day, \n",
    "                                                             n_samples_week, Y, data_source, target, \n",
    "                                                             outlier_removal, start_learnset,\n",
    "                                                             current_model_version, current_data_version, \n",
    "                                                             start_prediction, end_prediction, min_train_samples)\n",
    "    # Add predictions to final data frame\n",
    "    final_df = pd.concat([final_df, predictions], 0)\n",
    "    \n",
    "    # Get and store report figure\n",
    "    report_df = resono_pred.get_location_report_df(final_df, prepared_df, y_scaler, Y)\n",
    "    resono_pred.get_report_plot_hourly(report_df, legend, Y, report_dir, week_label)\n",
    "    resono_pred.get_report_plot_daily(report_df, Y, report_dir, week_label)\n",
    "    \n",
    "    # --- remove in version without backtesting\n",
    "    prepared_dfs[Y] = prepared_df\n",
    "    y_scalers[Y] = y_scaler\n",
    "    # ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check operational prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting --- remove code blocks below in version without backtesting\n",
    "\n",
    "Test model predictions for the selected location (argument at the beginning) and time period (start_test; within the time period for which the data has been prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for backtesting\n",
    "\n",
    "# Start testing from this timestamp until the most recent time slot\n",
    "start_test = \"2021-04-18 00:00:00\"\n",
    "# What period to predict for backtesting (samples)\n",
    "predict_period = n_samples_week*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a NN/LSTM model, it is necessary to also install these libraries\n",
    "# Related functions have to be uncommented in prediction_model_helpers.py\n",
    "#pip install keras\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backtesting\n",
    "\n",
    "# Store results\n",
    "locations = []\n",
    "rmse_benchmarks = []\n",
    "rmse_models = []\n",
    "figs_pred_time = dict()\n",
    "feat_imps = dict()\n",
    "figs_feat_imp = dict()\n",
    "\n",
    "# Predict for each location\n",
    "for idx, Y in enumerate(Y_names_all):\n",
    "    \n",
    "    # Show location\n",
    "    print(Y)\n",
    "    \n",
    "    # Prepare data\n",
    "    if Y in prepared_dfs:\n",
    "        df_y_predict_bt, df_y_train_bt, df_y_ground_truth_bt, df_y_ground_truth_bt_scaled, df_X_train_bt, df_X_predict_bt = h.prepare_backtesting(start_test, predict_period, freq, \n",
    "                                                                                   prepared_dfs[Y], Y, \n",
    "                                                                                   n_samples_week, target, y_scalers[Y])\n",
    "    \n",
    "    # Do not perform backtesting if there is not enough training data \n",
    "    if (df_X_train_bt.empty) | (len(df_X_train_bt) < min_train_samples):\n",
    "        print(\"Not enough training data: no backtesting performed.\")\n",
    "        continue\n",
    "    \n",
    "    # Benchmark predictions\n",
    "    df_y_benchmark = df_y_predict_bt.copy()\n",
    "    df_y_benchmark[Y] = h.test_model_past_week_bt(df_y_train_bt, df_y_predict_bt, df_y_ground_truth_bt_scaled, \n",
    "                                                    predict_period, \n",
    "                                                   n_samples_week, target)\n",
    "    if target == \"count\":\n",
    "        df_y_benchmark = h.unscale_y(df_y_benchmark, y_scalers[Y])\n",
    "        \n",
    "    error_metrics_benchmark = h.evaluate(df_y_benchmark, df_y_ground_truth_bt, target, Y_name = Y,\n",
    "                                         print_metrics = False)\n",
    "    \n",
    "    rmse_benchmarks.append(error_metrics_benchmark['rmse'])\n",
    "    \n",
    "    # Model predictions\n",
    "    df_y_model = df_y_predict_bt.copy()\n",
    "    \n",
    "    model = h.train_model_ridge_regression(df_X_train_bt, df_y_train_bt, Y, target)\n",
    "    df_y_model[Y] = h.test_model_ridge_regression(model, df_X_predict_bt)\n",
    "    if target == \"count\":\n",
    "        df_y_model = h.unscale_y(df_y_model, y_scalers[Y])\n",
    "    error_metrics_model = h.evaluate(df_y_model, df_y_ground_truth_bt, target, Y_name = Y, print_metrics = False)\n",
    "    \n",
    "    rmse_models.append(error_metrics_model['rmse'])\n",
    "    \n",
    "    # Visualize backtesting result\n",
    "    fig_pred_time = h.visualize_backtesting(df_y_ground_truth_bt, df_y_benchmark, df_y_model, target, Y, \n",
    "                                        error_metrics_model, y_label = \"Total visitor count\", count_to_level = False)\n",
    "    figs_pred_time[Y] = fig_pred_time\n",
    "    \n",
    "    # Feature importance\n",
    "    feat_imp, fig_feat_imp = h.feature_importance(model.coef_[0], list(df_X_train_bt.columns))\n",
    "    feat_imps[Y] = feat_imp\n",
    "    figs_feat_imp[Y] = fig_feat_imp\n",
    "    \n",
    "    locations.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting results for all locations\n",
    "df_results = h.backtesting_results_all_locations(locations, rmse_models, rmse_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarized results\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations for which the model performs better\n",
    "df_results[df_results['RMSE_difference'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations for which the benchmark model performs better\n",
    "df_results[df_results['RMSE_difference'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query results for specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['Location'] == \"Kalverstraat Noord\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_pred_time[\"Kalverstraat Noord\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_feat_imp[\"Kalverstraat Noord\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
