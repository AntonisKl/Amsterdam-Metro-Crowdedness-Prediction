{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resono 2h predictions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make 2h-ahead predictions of the visitor counts ('total_count' column in the 'ingested.resono' table) for all or a selection of Resono locations that are included in druktebeeld. \n",
    "\n",
    "Predictions are written to a new table **'public.resono_2h_pred_count'** or **'public.resono_2h_pred_level'** (depending on whether the visitor counts or crowd levels are predicted) with the following additional columns: \n",
    "- **'total_count_predicted'**/**'crowd_level_predicted'**: predicted total counts/crowd levels (for the next 8 time slots per location) \n",
    "- **'data_version'**: version of the data (feature set)\n",
    "- **'model_version'**: version of the model (type and settings)\n",
    "- **'predicted_at'**: timestamp of prediction (moment prediction was made)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations\n",
    "\n",
    "Change directory to folder that contains the DB credentials/folder that contains the function files in code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    # (Re-)Installs packages.\n",
    "    \n",
    "    get_ipython().run_cell_magic('bash', '', 'pip install imblearn\\npip install mord\\npip install psycopg2-binary\\npip install workalendar\\npip install eli5\\n pip install plotly')\n",
    "    \n",
    "    import pandas as pd\n",
    "    pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn==0.24.2  # Run if sklearn error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir(\"/home/jovyan/Crowd-prediction/Credentials\")\n",
    "import env_az\n",
    "os.chdir(\"/home/jovyan/gitops/central_storage_analyses/notebooks_predictions/resono_2h\")\n",
    "import prediction_model_helpers_bt as h  # Universal predictions\n",
    "import resono_2h_predictions_bt as resono_pred  # Resono 2h model specific\n",
    "#import importlib  # For when coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments for functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of sampling for data source to predict\n",
    "freq = '15min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what period to predict for operational forecast (samples)\n",
    "predict_period = 8\n",
    "# how many samples in a day\n",
    "n_samples_day = 96\n",
    "# how many samples in a week\n",
    "n_samples_week = n_samples_day*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of column name(s) of variabe to predict (can also be \"all\")\n",
    "#Y_names = \"all\" \n",
    "Y_names = [\"Albert Cuyp\", \"De Dam West\", \"De Dam Oost\", \"Kalverstraat Noord\", \"Kalverstraat Zuid\",\n",
    "          \"Vondelpark Oost 1\", \"Vondelpark Oost 2\", \"Vondelpark Oost 3\", \"Vondelpark West\",\n",
    "          \"Rembrandtplein\", \"Leidseplein\", \"Nieuwmarkt\", \"Buikslotermeerplein\",\n",
    "          \"Rembrandtpark\", \"Westerpark Centrum\", \"Westerpark West\", \"Westerpark Oost\",\n",
    "          \"Oosterpark\", \"Erasmuspark\", \"Flevopark\",\n",
    "          \"Park Frankendael\", \"Park Somerlust\", \"Bijlmerplein\", \"Waterlooplein\", \"Sarphatipark\",\n",
    "          \"Rokin\", \"Spui\", \"Damrak\", \"Nieuwendijk\"]\n",
    "\n",
    "# data source (for which the predictions are made)\n",
    "data_source = 'resono'\n",
    "\n",
    "# type of prediction (count -> regression or level -> classification)\n",
    "target = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for model\n",
    "use_smote = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for starting of learnset \n",
    "start_learnset = h.get_start_learnset(train_length = 8, date_str = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform outlier removal (\"yes\" or \"no\")\n",
    "outlier_removal = \"yes\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set versions (for storing results)\n",
    "current_model_version = 'lr_0_0'\n",
    "current_data_version = \"1_0\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Prepare data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_df, resono_df, resono_df_raw, start_prediction, end_prediction, thresholds, Y_names_all = resono_pred.prepare_data(env_az, \n",
    "                                                                                                           freq, \n",
    "                                                                                                           predict_period, \n",
    "                                                                                                           n_samples_day, \n",
    "                                                                                                           Y_names, \n",
    "                                                                                                           target,\n",
    "                                                                                                           start_learnset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Make predictions and store in data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- remove in version without backtesting\n",
    "prepared_dfs = dict()\n",
    "y_scalers = dict()\n",
    "thresholds_scaled = dict()\n",
    "# ---\n",
    "\n",
    "# Initialize data frame with predictions\n",
    "final_df = pd.DataFrame()\n",
    "\n",
    "# Predict for each location\n",
    "for idx, Y in enumerate(Y_names_all):\n",
    "    \n",
    "    # Show location\n",
    "    print(Y)\n",
    "    \n",
    "    # Preprocessed data frame for this location\n",
    "    preprocessed_df = resono_pred.get_location_df(base_df, resono_df, Y)\n",
    "    \n",
    "    # Gather predictons for this location\n",
    "    prepared_df, predictions, y_scaler, thresholds_scaled_one = resono_pred.get_resono_predictions(preprocessed_df, resono_df_raw, freq, predict_period, n_samples_day, \n",
    "                                                             n_samples_week, Y, data_source, target, \n",
    "                                                             outlier_removal, start_learnset, use_smote,\n",
    "                                                             current_model_version, current_data_version, \n",
    "                                                             start_prediction, end_prediction, thresholds)\n",
    "\n",
    "    # Add predictions to final data frame\n",
    "    final_df = pd.concat([final_df, predictions], 0)\n",
    "    \n",
    "    # --- remove in version without backtesting\n",
    "    prepared_dfs[Y] = prepared_df\n",
    "    y_scalers[Y] = y_scaler\n",
    "    thresholds_scaled[Y] = thresholds_scaled_one\n",
    "    # ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###  Store data\n",
    "\n",
    "# if target == 'count':\n",
    "    #final_df.to_sql('resono_2h_pred_count', con = engine_azure, if_exists = 'append', index = False)\n",
    "# elif target == \"level\":\n",
    "    #final_df.to_sql('resono_2h_pred_level', con = engine_azure, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check operational prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtesting --- remove code blocks below in version without backtesting\n",
    "\n",
    "Test model predictions for the selected location (argument at the beginning) and time period (start_test; within the time period for which the data has been prepared)\n",
    "\n",
    "**Important**: If you test using dates further back in time you need to enlarge the training set for the operational predictions so that the backtesting set contains of enough data as well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for backtesting\n",
    "\n",
    "# Start testing from this timestamp until the most recent time slot\n",
    "start_test = \"2021-05-01 00:00:00\"\n",
    "# What period to predict for backtesting (samples)\n",
    "predict_period = 96*31\n",
    "\n",
    "# inputs for models\n",
    "use_smote = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using a NN/LSTM model, it is necessary to also install these libraries\n",
    "# Related functions have to be uncommented in prediction_model_helpers.py\n",
    "#pip install keras\n",
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform backtesting\n",
    "\n",
    "# Store results\n",
    "locations = []\n",
    "rmse_benchmarks = []\n",
    "rmse_models = []\n",
    "figs_pred_time = dict()\n",
    "figs_conf_mat = dict()\n",
    "feat_imps = dict()\n",
    "figs_feat_imp = dict()\n",
    "\n",
    "# Predict for each location\n",
    "for idx, Y in enumerate(Y_names_all):\n",
    "    \n",
    "    # Show location\n",
    "    print(Y)\n",
    "    \n",
    "    # Prepare data\n",
    "    df_y_predict_bt, df_y_train_bt, df_y_ground_truth_bt, df_y_ground_truth_bt_scaled, df_X_train_bt, df_X_predict_bt = h.prepare_backtesting(start_test, predict_period, freq, \n",
    "                                                                                   prepared_dfs[Y], Y, \n",
    "                                                                                   n_samples_week, target, y_scalers[Y])\n",
    "    \n",
    "    \n",
    "    # Do not perform backtesting if there is not enough training data \n",
    "    if df_X_train_bt.empty:\n",
    "        print(\"Not enough training data: no backtesting performed.\")\n",
    "        continue\n",
    "    \n",
    "    # Benchmark predictions\n",
    "    df_y_benchmark = df_y_predict_bt.copy()\n",
    "    df_y_benchmark[Y] = h.test_model_avg_3_weeks_bt(df_y_train_bt, df_y_predict_bt, df_y_ground_truth_bt_scaled, predict_period, \n",
    "                                                   n_samples_week, target)\n",
    "    if target == \"count\":\n",
    "        df_y_benchmark = h.unscale_y(df_y_benchmark, y_scalers[Y])\n",
    "        \n",
    "    error_metrics_benchmark = h.evaluate(df_y_benchmark, df_y_ground_truth_bt, target, count_to_level = True,\n",
    "                                     Y_name = Y, thresholds = thresholds, print_metrics = False)\n",
    "    \n",
    "    rmse_benchmarks.append(error_metrics_benchmark['rmse'])\n",
    "    \n",
    "    # Model predictions\n",
    "    df_y_model = df_y_predict_bt.copy()\n",
    "    \n",
    "    model = h.train_model_ridge_regression(df_X_train_bt, df_y_train_bt, Y, target, thresholds_all = thresholds_scaled, use_smote = use_smote)\n",
    "    df_y_model[Y] = h.test_model_ridge_regression(model, df_X_predict_bt)\n",
    "    if target == \"count\":\n",
    "        df_y_model = h.unscale_y(df_y_model, y_scalers[Y])\n",
    "    error_metrics_model = h.evaluate(df_y_model, df_y_ground_truth_bt, target, count_to_level = True,\n",
    "                                 Y_name = Y, thresholds = thresholds, print_metrics = False)\n",
    "    \n",
    "    rmse_models.append(error_metrics_model['rmse'])\n",
    "    \n",
    "    # Visualize backtesting result\n",
    "    fig_pred_time, fig_conf_mat = h.visualize_backtesting(df_y_ground_truth_bt, df_y_benchmark, df_y_model, target, Y, \n",
    "                                        error_metrics_model, count_to_level = True)\n",
    "    figs_pred_time[Y] = fig_pred_time\n",
    "    figs_conf_mat[Y] = fig_conf_mat\n",
    "    \n",
    "    # Feature importance\n",
    "    feat_imp, fig_feat_imp = h.feature_importance(model.coef_[0], list(df_X_train_bt.columns))\n",
    "    feat_imps[Y] = feat_imp\n",
    "    figs_feat_imp[Y] = fig_feat_imp\n",
    "    \n",
    "    locations.append(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backtesting results for all locations\n",
    "df_results = h.backtesting_results_all_locations(locations, rmse_models, rmse_benchmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarized results\n",
    "df_results.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locations for which the benchmark model performs better\n",
    "df_results[df_results['RMSE_difference'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Query results for specific location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results[df_results['Location'] == \"Albert Cuyp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_pred_time[\"Albert Cuyp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_conf_mat[\"Albert Cuyp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs_feat_imp[\"Albert Cuyp\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
