{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ^^^ pyforest auto-imports - don't write above this line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# General Modelling Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: change directories to folder that contains credentials/helper functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_packages():\n",
    "    # (Re-)Installs packages.\n",
    "    \n",
    "    get_ipython().run_cell_magic('bash', '', 'pip install keras\\npip install tensorflow\\npip install imblearn\\npip install mord\\npip install psycopg2-binary\\npip install workalendar\\npip install eli5\\n pip install plotly')\n",
    "    \n",
    "    pd.set_option('mode.chained_assignment', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "install_packages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine, inspect\n",
    "\n",
    "os.chdir(\"/home/jovyan/Crowd-prediction/Credentials\")\n",
    "import env\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import substring, length, col, expr\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "import requests\n",
    "\n",
    "from datetime import datetime, timedelta, date\n",
    "import pytz\n",
    "from workalendar.europe import Netherlands\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "os.chdir(\"/home/jovyan/Crowd-prediction/Operational_code\")\n",
    "import helpers as h\n",
    "\n",
    "import importlib   # to reload helpers without restarting kernel: importlib.reload(h)\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importlib.reload(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Database connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine_azure, table_names = h.prepare_engine(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Arguments for functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# frequency of sampling for data source to predict\n",
    "freq = '15min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what period to predict for operational forecast (samples)\n",
    "predict_period = 8\n",
    "# how many samples in a day\n",
    "n_samples_day = 96\n",
    "# how many samples in a week\n",
    "n_samples_week = n_samples_day*7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# column name(s) of variable to predict (can also be \"all\")\n",
    "Y_name = \"Vondelpark Oost\" \n",
    "\n",
    "# data source (for which the predictions are made)\n",
    "data_source = 'resono'\n",
    "\n",
    "# type of prediction (count -> regression or level -> classification)\n",
    "target = 'count'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location names of CMSA and parking data\n",
    "cmsa_location = 'Stadhouderskade' \n",
    "cmsa_location_new = 'Stadhouderskade_cmsa' # To fix possible overlap resono and cmsa location names\n",
    "parking_location = 'CE-P06 Byzantium' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs for models\n",
    "batch_size = 5\n",
    "epochs = 10\n",
    "neurons = 10\n",
    "drop_out_perc = 0.2\n",
    "tune_hyperparameters = False\n",
    "use_sample_weights = False\n",
    "use_smote = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input for starting of learnset \n",
    "start_learnset = h.get_start_learnset(train_length = 16, date_str = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform outlier removal (\"yes\" or \"no\")\n",
    "outlier_removal = \"no\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set versions (for storing results)\n",
    "current_model_version = 'lr_0_0'\n",
    "current_data_version = \"1_0\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define vacations (we might want to put this in a database table in the future)\n",
    "kerst_19 = pd.DataFrame(data = {'date': pd.date_range(date(2019, 12, 21), periods = 7*2 + 2, freq='1d')})\n",
    "voorjaar_20 = pd.DataFrame(data = {'date': pd.date_range(date(2020, 2, 15), periods = 9, freq='1d')})\n",
    "mei_20 = pd.DataFrame(data = {'date': pd.date_range(date(2020, 4, 25), periods = 9, freq='1d')})\n",
    "zomer_20 = pd.DataFrame(data = {'date': pd.date_range(date(2020, 7, 4), periods = 7*6 + 2, freq='1d')})\n",
    "herfst_20 = pd.DataFrame(data = {'date': pd.date_range(date(2020, 10, 10), periods = 9, freq='1d')})\n",
    "kerst_20 = pd.DataFrame(data = {'date': pd.date_range(date(2020, 12, 19), periods = 7*2 + 2, freq='1d')})\n",
    "voorjaar_21 = pd.DataFrame(data = {'date': pd.date_range(date(2021, 2, 20), periods = 9, freq='1d')})\n",
    "mei_21 = pd.DataFrame(data = {'date': pd.date_range(date(2021, 5, 1), periods = 9, freq='1d')})\n",
    "zomer_21 = pd.DataFrame(data = {'date': pd.date_range(date(2021, 7, 10), periods = 7*6 + 2, freq='1d')})\n",
    "herfst_21 = pd.DataFrame(data = {'date': pd.date_range(date(2021, 10, 16), periods = 9, freq='1d')})\n",
    "kerst_21 = pd.DataFrame(data = {'date': pd.date_range(date(2021, 12, 25), periods = 7*2 + 2, freq='1d')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start loading raw data') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resono_df_raw = h.get_data(engine_azure, \"ingested.resono\", Y_name, start_learnset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select moment to end operational forecast based on last value of variable to predict in database\n",
    "\n",
    "# Resono example\n",
    "start_prediction = pd.date_range(resono_df_raw[\"measured_at\"].max(), periods = 2, freq = freq)[1]\n",
    "end_prediction = pd.date_range(start_prediction, periods = predict_period, freq = freq)\n",
    "end_prediction = end_prediction[len(end_prediction)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsa_df_raw = h.get_data(engine_azure, \"ingested.cmsa\", cmsa_location, start_learnset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_df_raw = h.get_data(engine_azure, \"ingested.parking\", parking_location, start_learnset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays_data_raw = Netherlands().holidays(2020) + Netherlands().holidays(2021) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_df_raw = kerst_19.append([voorjaar_20, mei_20, zomer_20, herfst_20, kerst_20,\n",
    "                                   voorjaar_21, mei_21, zomer_21, herfst_21, kerst_21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_url = 'https://covidtrackerapi.bsg.ox.ac.uk/api/v2/stringency/date-range/'+ str(start_learnset) + \"/\" + str(start_prediction)\n",
    "covid_df_raw = pd.DataFrame(requests.get(url = covid_url).json()['data'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start pre-processing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resono_df = h.preprocess_resono_data(resono_df_raw, freq, end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmsa_df = h.preprocess_cmsa_data(cmsa_df_raw, freq, end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parking_df = h.preprocess_parking_data(parking_df_raw, freq, end_prediction, remove_ceiling = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_df = h.preprocess_covid_data(covid_df_raw, freq, end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holiday_df = h.preprocess_holidays_data(holidays_data_raw, freq, end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vacation_df = h.preprocess_vacation_data(vacation_df_raw, freq, end_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-process any other data sources here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join data\n",
    "df = resono_df.join(cmsa_df).join(parking_df).join(covid_df).join(holiday_df).join(vacation_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start cleaning data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute/drop missing data and substitute outliers\n",
    "cols_to_clean = [parking_location] + [cmsa_location_new]\n",
    "df = h.clean_data(df, target, Y_name, n_samples_day, cols_to_clean = cols_to_clean, outlier_removal = outlier_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add time features\n",
    "df = h.add_time_variables(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new features from the data\n",
    "df = h.add_lag_variables(df, Y_name, target, predict_period, n_samples_day, n_samples_week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter data based on start learnset\n",
    "df = df[start_learnset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop time slots for which missing values remain\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale dataset\n",
    "df, y_scaler = h.scale_variables(df, Y_name, target, method = \"standard\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Create model dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_train, df_y_train = h.get_train_df(df, Y_name, start_prediction) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_predict = h.get_future_df(start_prediction, predict_period, freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X_predict = df.drop(Y_name, 1)\n",
    "\n",
    "# For variables that are not known yet, use historical values\n",
    "for col in cols_to_clean:\n",
    "    df_X_predict[col] = df_X_predict[col].shift(n_samples_week)\n",
    "\n",
    "# Select features for prediction period\n",
    "df_X_predict = df_X_predict[start_prediction:end_prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create operational prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start modelling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = h.train_model_linear_regression(df_X_train, df_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_y_predict[Y_name] = h.test_model_linear_regression(model, df_X_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unscale prediction\n",
    "if target == \"count\":\n",
    "    df_y_predict = h.unscale_y(df_y_predict, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Prepare output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start preparing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = h.prepare_final_dataframe(df_y_predict, resono_df_raw, data_source, target, current_model_version, current_data_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Store data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Start storing data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resono example\n",
    "\n",
    "#final_df.to_sql('resono_predictions_test', con = engine_azure, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Finished storing data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Check operational prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Backtesting "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare training and test data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input for backtesting\n",
    "\n",
    "# Start testing from this timestamp until the most recent time slot\n",
    "start_test = \"2021-04-01 00:00:00\"\n",
    "# What period to predict for backtesting (samples)\n",
    "predict_period = 96*30\n",
    "\n",
    "# inputs for models\n",
    "prediction_window = 8\n",
    "batch_size = 2\n",
    "epochs = 10\n",
    "neurons = 20\n",
    "drop_out_perc = 0.2\n",
    "learning_rate = 0.01\n",
    "tune_hyperparameters = False\n",
    "use_smote = True\n",
    "use_sample_weights = False\n",
    "\n",
    "# columns for which we need future values\n",
    "cols_unknown = [parking_location] + [cmsa_location_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data\n",
    "df_y_predict_bt, df_y_train_bt, df_y_ground_truth_bt, df_y_ground_truth_bt_scaled, df_X_train_bt, df_X_predict_bt = h.prepare_backtesting(start_test, predict_period, freq, \n",
    "                                                                                   df, Y_name, cols_unknown, \n",
    "                                                                                   n_samples_week, target, y_scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, predict and evaluate benchmark model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark predictions\n",
    "df_y_benchmark = df_y_predict_bt.copy()\n",
    "df_y_benchmark[Y_name] = h.test_model_avg_3_weeks_bt(df_y_train_bt, df_y_predict_bt, df_y_ground_truth_bt_scaled, predict_period, \n",
    "                                                   n_samples_week, target)\n",
    "if target == \"count\":\n",
    "    df_y_benchmark = h.unscale_y(df_y_benchmark, y_scaler)\n",
    "error_metrics_benchmark = h.evaluate(df_y_benchmark, df_y_ground_truth_bt, target, print_metrics = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train, predict and evaluate models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model predictions\n",
    "df_y_model = df_y_predict_bt.copy()\n",
    "model = h.train_model_linear_regression(df_X_train_bt, df_y_train_bt)\n",
    "df_y_model[Y_name] = h.test_model_linear_regression(model, df_X_predict_bt)\n",
    "if target == \"count\":\n",
    "    df_y_model = h.unscale_y(df_y_model, y_scaler)\n",
    "error_metrics_model = h.evaluate(df_y_model, df_y_ground_truth_bt, target, print_metrics = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize backtesting result\n",
    "fig = h.visualize_backtesting(df_y_ground_truth_bt, df_y_benchmark, df_y_model, target, Y_name, error_metrics_model)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tune (hyper-)parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance, fig = h.feature_importance(model.coef_[0], list(df_X_train_bt.columns))\n",
    "fig"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
